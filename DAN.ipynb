{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO6shi0tRY3/CMJAgNWs2Sj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/samiha-mahin/A_Deep_Learning_Repo/blob/main/DAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **DAN (Deep & Cross Network)**\n",
        "\n",
        "---\n",
        "\n",
        "# What is DAN (Deep & Cross Network)?\n",
        "\n",
        "**DAN** stands for **Deep & Cross Network**. It's a neural network architecture designed to efficiently model both **explicit feature interactions** (like in factorization machines) and **deep nonlinear feature interactions**.\n",
        "\n",
        "---\n",
        "\n",
        "# Why DAN?\n",
        "\n",
        "* Traditional models like **logistic regression** capture only **linear relationships**.\n",
        "* Deep neural networks capture complex, **nonlinear feature interactions** but sometimes fail to explicitly model low-order feature crosses.\n",
        "* Feature crossing (interactions between features) is very important in applications like recommendation systems and ads.\n",
        "* DAN combines a **cross network** (which explicitly models bounded-degree feature crosses) with a **deep network** (which models higher-order, nonlinear interactions).\n",
        "\n",
        "---\n",
        "\n",
        "# Architecture of DAN\n",
        "\n",
        "DAN consists of two main parts, working in parallel:\n",
        "\n",
        "### 1. Cross Network (Explicit Crosses)\n",
        "\n",
        "* This network models **explicit feature crosses** of bounded degree.\n",
        "* Given input $x_0$, the cross network outputs layers $x_1, x_2, ..., x_L$ where each layer is:\n",
        "\n",
        "$$\n",
        "x_{l+1} = x_0 \\cdot (x_l^T w_l) + b_l + x_l\n",
        "$$\n",
        "\n",
        "* Here:\n",
        "\n",
        "  * $x_0$ is the original input vector.\n",
        "  * $w_l$ is a learnable weight vector.\n",
        "  * $b_l$ is a bias.\n",
        "* This operation explicitly models cross terms like $x_i x_j$, $x_i x_j x_k$ etc., in a controlled way.\n",
        "\n",
        "### 2. Deep Network (Nonlinear Interactions)\n",
        "\n",
        "* A standard feed-forward neural network with several fully connected layers and nonlinear activations.\n",
        "* It captures **complex, high-order feature interactions** implicitly.\n",
        "\n",
        "### 3. Concatenation and Output\n",
        "\n",
        "* Outputs of the Cross Network and Deep Network are concatenated.\n",
        "* Followed by a final linear layer and activation for prediction.\n",
        "\n",
        "---\n",
        "\n",
        "# Why is this useful?\n",
        "\n",
        "* Efficiently captures both **low-degree explicit feature crosses** and **complex nonlinear interactions**.\n",
        "* Works well for tabular data, especially in CTR prediction, recommendation, and advertising.\n",
        "\n",
        "---\n",
        "\n",
        "# Example Use Case\n",
        "\n",
        "Suppose you have features like:\n",
        "\n",
        "* User age\n",
        "* User gender\n",
        "* Ad category\n",
        "* Device type\n",
        "\n",
        "You want to predict if a user will click an ad (binary classification).\n",
        "\n",
        "* Cross network might explicitly model interactions like (User age) × (Ad category).\n",
        "* Deep network might model complex nonlinear patterns across all features.\n",
        "* DAN combines these for better predictive power.\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# Summary\n",
        "\n",
        "| Aspect          | Explanation                                          |\n",
        "| --------------- | ---------------------------------------------------- |\n",
        "| Purpose         | Model explicit and implicit feature interactions     |\n",
        "| Cross Network   | Models low-degree explicit feature crosses           |\n",
        "| Deep Network    | Models nonlinear, high-order interactions            |\n",
        "| Combined Output | Concatenation for final prediction                   |\n",
        "| Use Cases       | CTR prediction, recommendation systems, tabular data |\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "sQBY8Lib0aTB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, Model\n",
        "\n",
        "class CrossLayer(layers.Layer):\n",
        "    def __init__(self, input_dim):\n",
        "        super().__init__()\n",
        "        self.w = self.add_weight(shape=(input_dim,), initializer='random_normal', trainable=True)\n",
        "        self.b = self.add_weight(shape=(input_dim,), initializer='zeros', trainable=True)\n",
        "\n",
        "    def call(self, x0, x):\n",
        "        xw = tf.reduce_sum(x * self.w, axis=1, keepdims=True)\n",
        "        return x0 * xw + self.b + x\n",
        "\n",
        "class DeepCrossNetwork(Model):\n",
        "    def __init__(self, input_dim):\n",
        "        super().__init__()\n",
        "        self.cross1 = CrossLayer(input_dim)\n",
        "        self.cross2 = CrossLayer(input_dim)\n",
        "        self.dense1 = layers.Dense(64, activation='relu')\n",
        "        self.dense2 = layers.Dense(32, activation='relu')\n",
        "        self.output_layer = layers.Dense(1, activation='sigmoid')\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x0 = inputs\n",
        "        x = self.cross1(x0, x0)\n",
        "        x = self.cross2(x0, x)\n",
        "        deep_out = self.dense1(x0)\n",
        "        deep_out = self.dense2(deep_out)\n",
        "        combined = tf.concat([x, deep_out], axis=1)\n",
        "        return self.output_layer(combined)\n"
      ],
      "metadata": {
        "id": "4Q0iepMl1NV6"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load Titanic data (example)\n",
        "df = pd.read_csv('titanic.csv')\n",
        "\n",
        "# Preprocessing (simple example)\n",
        "df['Age'].fillna(df['Age'].median(), inplace=True)\n",
        "df['Fare'].fillna(df['Fare'].median(), inplace=True)\n",
        "df['Embarked'].fillna('S', inplace=True)\n",
        "\n",
        "# Select features and target\n",
        "features = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']\n",
        "X = df[features]\n",
        "y = df['Survived'].values\n",
        "\n",
        "# Encode categorical variables\n",
        "X = pd.get_dummies(X, columns=['Sex', 'Embarked'])\n",
        "\n",
        "# Scale numerical features\n",
        "scaler = StandardScaler()\n",
        "for col in ['Age', 'Fare']:\n",
        "    X[col] = scaler.fit_transform(X[[col]])\n",
        "\n",
        "X = X.values.astype(np.float32)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Define your DAN model (as shared earlier)...\n",
        "\n",
        "input_dim = X_train.shape[1]\n",
        "model = DeepCrossNetwork(input_dim=input_dim)\n",
        "\n",
        "# Compile\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train\n",
        "model.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs=50, batch_size=32)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = (model.predict(X_valid) > 0.5).astype(int)\n",
        "print(\"Validation Accuracy:\", accuracy_score(y_valid, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1p5xeDx20xum",
        "outputId": "ac9dfa75-ab05-4e08-f269-eeeddc6012bd"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-5-2066763222.py:12: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['Age'].fillna(df['Age'].median(), inplace=True)\n",
            "/tmp/ipython-input-5-2066763222.py:13: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['Fare'].fillna(df['Fare'].median(), inplace=True)\n",
            "/tmp/ipython-input-5-2066763222.py:14: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['Embarked'].fillna('S', inplace=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.6403 - loss: 0.6495 - val_accuracy: 0.6927 - val_loss: 0.5696\n",
            "Epoch 2/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7402 - loss: 0.5296 - val_accuracy: 0.7765 - val_loss: 0.5260\n",
            "Epoch 3/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7738 - loss: 0.5079 - val_accuracy: 0.8045 - val_loss: 0.5017\n",
            "Epoch 4/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7959 - loss: 0.4639 - val_accuracy: 0.8045 - val_loss: 0.4868\n",
            "Epoch 5/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8196 - loss: 0.4394 - val_accuracy: 0.8045 - val_loss: 0.4773\n",
            "Epoch 6/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7934 - loss: 0.4599 - val_accuracy: 0.8156 - val_loss: 0.4686\n",
            "Epoch 7/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7968 - loss: 0.4360 - val_accuracy: 0.8156 - val_loss: 0.4640\n",
            "Epoch 8/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8288 - loss: 0.4040 - val_accuracy: 0.8101 - val_loss: 0.4582\n",
            "Epoch 9/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8101 - loss: 0.4241 - val_accuracy: 0.8212 - val_loss: 0.4538\n",
            "Epoch 10/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8151 - loss: 0.4207 - val_accuracy: 0.8212 - val_loss: 0.4558\n",
            "Epoch 11/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8285 - loss: 0.4210 - val_accuracy: 0.8045 - val_loss: 0.4471\n",
            "Epoch 12/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8275 - loss: 0.3976 - val_accuracy: 0.8156 - val_loss: 0.4460\n",
            "Epoch 13/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8366 - loss: 0.4042 - val_accuracy: 0.8156 - val_loss: 0.4464\n",
            "Epoch 14/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8264 - loss: 0.4076 - val_accuracy: 0.8156 - val_loss: 0.4404\n",
            "Epoch 15/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8123 - loss: 0.4298 - val_accuracy: 0.8212 - val_loss: 0.4413\n",
            "Epoch 16/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8386 - loss: 0.3754 - val_accuracy: 0.8212 - val_loss: 0.4391\n",
            "Epoch 17/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8289 - loss: 0.4043 - val_accuracy: 0.8212 - val_loss: 0.4375\n",
            "Epoch 18/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8269 - loss: 0.4108 - val_accuracy: 0.8156 - val_loss: 0.4433\n",
            "Epoch 19/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8344 - loss: 0.3979 - val_accuracy: 0.8101 - val_loss: 0.4415\n",
            "Epoch 20/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8376 - loss: 0.3903 - val_accuracy: 0.8045 - val_loss: 0.4456\n",
            "Epoch 21/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8095 - loss: 0.4202 - val_accuracy: 0.8101 - val_loss: 0.4386\n",
            "Epoch 22/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8634 - loss: 0.3784 - val_accuracy: 0.8101 - val_loss: 0.4387\n",
            "Epoch 23/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8508 - loss: 0.3900 - val_accuracy: 0.8156 - val_loss: 0.4374\n",
            "Epoch 24/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8680 - loss: 0.3632 - val_accuracy: 0.8156 - val_loss: 0.4355\n",
            "Epoch 25/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8488 - loss: 0.3800 - val_accuracy: 0.8045 - val_loss: 0.4354\n",
            "Epoch 26/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8685 - loss: 0.3642 - val_accuracy: 0.8156 - val_loss: 0.4389\n",
            "Epoch 27/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8624 - loss: 0.3647 - val_accuracy: 0.7989 - val_loss: 0.4349\n",
            "Epoch 28/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8281 - loss: 0.4136 - val_accuracy: 0.8045 - val_loss: 0.4338\n",
            "Epoch 29/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8337 - loss: 0.3795 - val_accuracy: 0.7989 - val_loss: 0.4324\n",
            "Epoch 30/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8541 - loss: 0.3591 - val_accuracy: 0.7989 - val_loss: 0.4363\n",
            "Epoch 31/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8546 - loss: 0.3592 - val_accuracy: 0.7989 - val_loss: 0.4311\n",
            "Epoch 32/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8625 - loss: 0.3635 - val_accuracy: 0.7989 - val_loss: 0.4342\n",
            "Epoch 33/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8553 - loss: 0.3642 - val_accuracy: 0.7989 - val_loss: 0.4317\n",
            "Epoch 34/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8514 - loss: 0.3651 - val_accuracy: 0.8101 - val_loss: 0.4334\n",
            "Epoch 35/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8348 - loss: 0.3801 - val_accuracy: 0.7989 - val_loss: 0.4332\n",
            "Epoch 36/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8504 - loss: 0.3723 - val_accuracy: 0.7933 - val_loss: 0.4319\n",
            "Epoch 37/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8483 - loss: 0.3621 - val_accuracy: 0.7933 - val_loss: 0.4314\n",
            "Epoch 38/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8519 - loss: 0.3698 - val_accuracy: 0.7989 - val_loss: 0.4331\n",
            "Epoch 39/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8591 - loss: 0.3437 - val_accuracy: 0.7933 - val_loss: 0.4321\n",
            "Epoch 40/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8580 - loss: 0.3537 - val_accuracy: 0.7933 - val_loss: 0.4309\n",
            "Epoch 41/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8561 - loss: 0.3619 - val_accuracy: 0.7877 - val_loss: 0.4310\n",
            "Epoch 42/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8748 - loss: 0.3158 - val_accuracy: 0.7877 - val_loss: 0.4358\n",
            "Epoch 43/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8328 - loss: 0.3741 - val_accuracy: 0.7877 - val_loss: 0.4296\n",
            "Epoch 44/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8522 - loss: 0.3698 - val_accuracy: 0.7877 - val_loss: 0.4328\n",
            "Epoch 45/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8452 - loss: 0.3859 - val_accuracy: 0.7877 - val_loss: 0.4331\n",
            "Epoch 46/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8527 - loss: 0.3483 - val_accuracy: 0.7989 - val_loss: 0.4345\n",
            "Epoch 47/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8387 - loss: 0.3675 - val_accuracy: 0.7821 - val_loss: 0.4341\n",
            "Epoch 48/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8617 - loss: 0.3440 - val_accuracy: 0.7821 - val_loss: 0.4337\n",
            "Epoch 49/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8505 - loss: 0.3649 - val_accuracy: 0.7933 - val_loss: 0.4320\n",
            "Epoch 50/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8494 - loss: 0.3712 - val_accuracy: 0.8101 - val_loss: 0.4422\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "Validation Accuracy: 0.8100558659217877\n"
          ]
        }
      ]
    }
  ]
}