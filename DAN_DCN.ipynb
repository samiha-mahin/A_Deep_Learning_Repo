{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM8gl+nYaHZnwmCaXXMTJeC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/samiha-mahin/A_Deep_Learning_Repo/blob/main/DAN_DCN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **DAN (Deep Attention Network)**\n",
        "\n",
        "## üåü What is a **DAN (Deep Attention Network)?**\n",
        "\n",
        "A **DAN** is a neural network that uses **attention mechanisms** to automatically **weigh and prioritize features or interactions**. It is **especially useful for structured/tabular data** (like user clicks, e-commerce, medical data) where not all features contribute equally.\n",
        "\n",
        "---\n",
        "\n",
        "## üß† **Core Idea of DAN**\n",
        "\n",
        "Instead of treating all input features equally, **DAN assigns different weights to features or feature pairs**, helping the model \"pay attention\" to the most relevant parts of the input.\n",
        "\n",
        "---\n",
        "\n",
        "## üìê Example: E-commerce User Click Prediction (DIN Model)\n",
        "\n",
        "Let‚Äôs say you want to predict whether a user will click on a product. You have:\n",
        "\n",
        "* User features: age, gender, location\n",
        "* Product features: category, price, brand\n",
        "* User behavior history: list of past clicked items\n",
        "\n",
        "### üîç In DAN:\n",
        "\n",
        "* The model uses **attention** to decide **which past clicked items** are most relevant to the current product.\n",
        "* If the user previously clicked many electronics, attention will **assign more weight to those** while comparing with a new electronics item.\n",
        "\n",
        "---\n",
        "\n",
        "## üèóÔ∏è Architecture (Example: **DIN ‚Äì Deep Interest Network**)\n",
        "\n",
        "```\n",
        "Input (user, product, history)\n",
        "      |\n",
        "Embedding Layers (for sparse features)\n",
        "      |\n",
        "Attention Layer (over user history, conditioned on current item)\n",
        "      |\n",
        "Weighted Summation (outputs interest vector)\n",
        "      |\n",
        "MLP Layers (dense)\n",
        "      |\n",
        "Output (probability of click)\n",
        "```\n",
        "\n",
        "üß† The **attention layer** computes weights like:\n",
        "\n",
        "```math\n",
        "Œ±·µ¢ = softmax(Attention(query=current_item, key=history_item·µ¢))\n",
        "```\n",
        "\n",
        "This gives us a **customized interest representation** per input.\n",
        "\n",
        "---\n",
        "\n",
        "## ‚úÖ Common **DAN-Based Models**\n",
        "\n",
        "| Model                     | Name                                                                 | Description                                                                      |\n",
        "| ------------------------- | -------------------------------------------------------------------- | -------------------------------------------------------------------------------- |\n",
        "| **DIN**                   | Deep Interest Network                                                | First popular DAN for CTR prediction; uses attention on user behavior.           |\n",
        "| **DIEN**                  | Deep Interest Evolution Network                                      | Adds time sequence modeling (GRU + attention) to DIN.                            |\n",
        "| **AutoInt**               | Automatic Feature Interaction Learning                               | Uses multi-head self-attention to model feature interactions like a Transformer. |\n",
        "| **FiBiNET**               | Feature Interaction Bilinear Network                                 | Combines **bilinear pooling** and **SE-attention** (Squeeze-Excitation).         |\n",
        "| **AFN**                   | Adaptive Factorization Network                                       | Uses attention to combine low-order and high-order features.                     |\n",
        "| **DeepFM with Attention** | Extension of DeepFM with an attention layer over feature embeddings. |                                                                                  |\n",
        "\n",
        "---\n",
        "\n",
        "## üìä When to Use DAN?\n",
        "\n",
        "Use DAN when:\n",
        "\n",
        "* You have **tabular or sparse data** with many features (e.g., recommender systems, medical diagnosis, insurance).\n",
        "* You want to model **interactions** between features **automatically**.\n",
        "* You need **interpretability** ‚Äî attention weights can show what the model focused on.\n",
        "\n",
        "---\n",
        "\n",
        "## üîß Example in Code (Simplified TensorFlow-like)\n",
        "\n",
        "```python\n",
        "# Example: attention over item history (simplified)\n",
        "def attention(query, keys):\n",
        "    scores = tf.matmul(query, keys, transpose_b=True)  # [batch, 1, seq]\n",
        "    weights = tf.nn.softmax(scores)\n",
        "    output = tf.matmul(weights, keys)  # weighted sum\n",
        "    return output\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## üß† Summary: DAN vs Others\n",
        "\n",
        "| Feature                   | DAN                    | DCN              | DNN              |\n",
        "| ------------------------- | ---------------------- | ---------------- | ---------------- |\n",
        "| Attention Layer           | ‚úÖ Yes                  | ‚ùå No             | ‚ùå No             |\n",
        "| Learns Feature Importance | ‚úÖ Yes                  | ‚ö†Ô∏è Implicit      | ‚ùå No             |\n",
        "| Feature Interaction       | ‚úÖ High-order (dynamic) | ‚úÖ Explicit Cross | ‚ö†Ô∏è Implicit only |\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "d-MDB7OH10c3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **PCOS Dataset for DCN**"
      ],
      "metadata": {
        "id": "3P9GgQFFyjQ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('/content/balanced_pcos_dataset.csv')\n",
        "df.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "id": "2zlY-UTwyPkB",
        "outputId": "279441ea-6819-4f97-ebe4-15a573aafe6c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Cycle length(days)  Follicle No. (L)  LH(mIU/mL)  Vit D3 (ng/mL)  \\\n",
              "0             0.35226          0.367547    0.681895        0.351906   \n",
              "1             0.35226          0.852723    0.242159        0.934335   \n",
              "2             0.35226          0.278762    0.516913        0.685269   \n",
              "3             0.35226          0.367547    0.247008        0.850480   \n",
              "4             0.35226          0.704772    0.286487        0.970809   \n",
              "\n",
              "   Weight (Kg)  Follicle No. (R)  AMH(ng/mL)  Cycle(R/I)_4  Fast food (Y/N)  \\\n",
              "0     0.232116          0.356109    0.390070           0.0              1.0   \n",
              "1     0.711340          0.912169    0.753844           0.0              1.0   \n",
              "2     0.636452          0.268632    0.264623           0.0              0.0   \n",
              "3     0.379283          0.429758    0.413539           0.0              0.0   \n",
              "4     0.815596          0.551295    0.759701           0.0              0.0   \n",
              "\n",
              "   Skin darkening (Y/N)  Weight gain(Y/N)  Pimples(Y/N)  hair growth(Y/N)  \\\n",
              "0                   0.0               0.0           0.0               0.0   \n",
              "1                   0.0               0.0           1.0               0.0   \n",
              "2                   0.0               0.0           0.0               0.0   \n",
              "3                   0.0               0.0           0.0               0.0   \n",
              "4                   0.0               1.0           0.0               0.0   \n",
              "\n",
              "   PCOS (Y/N)  \n",
              "0         0.0  \n",
              "1         1.0  \n",
              "2         0.0  \n",
              "3         0.0  \n",
              "4         0.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-365b6c23-f1de-4419-aa62-29284ae1c4f1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Cycle length(days)</th>\n",
              "      <th>Follicle No. (L)</th>\n",
              "      <th>LH(mIU/mL)</th>\n",
              "      <th>Vit D3 (ng/mL)</th>\n",
              "      <th>Weight (Kg)</th>\n",
              "      <th>Follicle No. (R)</th>\n",
              "      <th>AMH(ng/mL)</th>\n",
              "      <th>Cycle(R/I)_4</th>\n",
              "      <th>Fast food (Y/N)</th>\n",
              "      <th>Skin darkening (Y/N)</th>\n",
              "      <th>Weight gain(Y/N)</th>\n",
              "      <th>Pimples(Y/N)</th>\n",
              "      <th>hair growth(Y/N)</th>\n",
              "      <th>PCOS (Y/N)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.35226</td>\n",
              "      <td>0.367547</td>\n",
              "      <td>0.681895</td>\n",
              "      <td>0.351906</td>\n",
              "      <td>0.232116</td>\n",
              "      <td>0.356109</td>\n",
              "      <td>0.390070</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.35226</td>\n",
              "      <td>0.852723</td>\n",
              "      <td>0.242159</td>\n",
              "      <td>0.934335</td>\n",
              "      <td>0.711340</td>\n",
              "      <td>0.912169</td>\n",
              "      <td>0.753844</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.35226</td>\n",
              "      <td>0.278762</td>\n",
              "      <td>0.516913</td>\n",
              "      <td>0.685269</td>\n",
              "      <td>0.636452</td>\n",
              "      <td>0.268632</td>\n",
              "      <td>0.264623</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.35226</td>\n",
              "      <td>0.367547</td>\n",
              "      <td>0.247008</td>\n",
              "      <td>0.850480</td>\n",
              "      <td>0.379283</td>\n",
              "      <td>0.429758</td>\n",
              "      <td>0.413539</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.35226</td>\n",
              "      <td>0.704772</td>\n",
              "      <td>0.286487</td>\n",
              "      <td>0.970809</td>\n",
              "      <td>0.815596</td>\n",
              "      <td>0.551295</td>\n",
              "      <td>0.759701</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-365b6c23-f1de-4419-aa62-29284ae1c4f1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-365b6c23-f1de-4419-aa62-29284ae1c4f1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-365b6c23-f1de-4419-aa62-29284ae1c4f1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-297dc5b5-22ff-4b4d-85e4-3a787fecb2ce\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-297dc5b5-22ff-4b4d-85e4-3a787fecb2ce')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-297dc5b5-22ff-4b4d-85e4-3a787fecb2ce button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 628,\n  \"fields\": [\n    {\n      \"column\": \"Cycle length(days)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.14356413035154417,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 157,\n        \"samples\": [\n          0.4227647274684917,\n          0.2499810440784116,\n          0.3388733488250393\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Follicle No. (L)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.22000287074226074,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 208,\n        \"samples\": [\n          0.7993960703570405,\n          0.8188939528790211,\n          0.7960050562534907\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"LH(mIU/mL)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2448650942679013,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 482,\n        \"samples\": [\n          0.5046019150107085,\n          0.7052293348274714,\n          0.6029597939212304\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Vit D3 (ng/mL)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1833522712468779,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 474,\n        \"samples\": [\n          0.5526314283209249,\n          0.3746139954653533,\n          0.3765310920810898\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Weight (Kg)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.17327945413358473,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 300,\n        \"samples\": [\n          0.5134345661536063,\n          0.9355524807425408,\n          0.6186421391363481\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Follicle No. (R)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2287168815163898,\n        \"min\": 0.0,\n        \"max\": 1.0000000000000002,\n        \"num_unique_values\": 206,\n        \"samples\": [\n          0.7755744005454144,\n          0.7366877297757635,\n          0.4330841069764594\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AMH(ng/mL)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.22694785648220098,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 440,\n        \"samples\": [\n          0.7134983526417281,\n          0.9049062988590124,\n          0.7267116266371856\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Cycle(R/I)_4\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.44972592486201546,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.1445394159889927,\n          0.3567117815576468,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Fast food (Y/N)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.48871599509947616,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 29,\n        \"samples\": [\n          0.7179654274286935,\n          0.2708322512620742,\n          0.578280140996174\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Skin darkening (Y/N)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.48227864209074994,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 22,\n        \"samples\": [\n          0.0,\n          0.5492266647061205,\n          0.8773730719279554\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Weight gain(Y/N)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.4929163245124754,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          0.0,\n          0.5857755812734633,\n          0.0407288023189701\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Pimples(Y/N)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.4962912057965961,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 18,\n        \"samples\": [\n          0.0,\n          1.0,\n          0.2739086662773384\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"hair growth(Y/N)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.47094833548790777,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.6014952656026266,\n          0.1774395437797228,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"PCOS (Y/N)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.5003985652286931,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1.0,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**DCN (Deep & Cross Network)**\n",
        "\n",
        "\n",
        "\n",
        "## üí° What is DCN (Deep & Cross Network)?\n",
        "\n",
        "**DCN**, or **Deep & Cross Network**, is a neural network architecture designed to handle **structured/tabular data** ‚Äî like patient records, ad features, survey data, etc. It‚Äôs especially powerful in tasks where **interactions between features** are important, but we don‚Äôt want to manually create all of them.\n",
        "\n",
        "It was introduced by **Google** for tasks like **Click-Through Rate (CTR) prediction**, and it works **brilliantly** for datasets like:\n",
        "\n",
        "* Medical diagnosis (like PCOS)\n",
        "* Insurance risk scoring\n",
        "* Recommender systems\n",
        "* Financial forecasting\n",
        "\n",
        "---\n",
        "\n",
        "## üéØ Why Was DCN Created?\n",
        "\n",
        "In traditional ML and even deep learning:\n",
        "\n",
        "* **Logistic Regression** only captures **linear relationships** between features.\n",
        "* **DNNs (Deep Neural Networks)** capture complex, nonlinear patterns, but **don‚Äôt explicitly** capture how features interact (e.g., BMI √ó Glucose).\n",
        "* **Manually adding feature crosses** is tedious, error-prone, and doesn‚Äôt scale well.\n",
        "\n",
        "So, DCN was designed to:\n",
        "\n",
        "1. **Automatically model feature interactions**\n",
        "2. **Also learn complex nonlinear patterns**\n",
        "3. Work efficiently even with **high-dimensional sparse data**\n",
        "\n",
        "---\n",
        "\n",
        "## üèóÔ∏è DCN Architecture ‚Äî How Does It Work?\n",
        "\n",
        "DCN has **two parallel parts**, like two brains working together:\n",
        "\n",
        "### üß† 1. Cross Network\n",
        "\n",
        "* Learns **explicit feature interactions**.\n",
        "* Think of this as **multiplying features together** in smart combinations.\n",
        "* For example:\n",
        "\n",
        "  * It might learn that `AMH √ó Vitamin D3` is important.\n",
        "  * Or that `BMI √ó Follicle Count` matters for PCOS.\n",
        "\n",
        "‚û° This network **doesn‚Äôt just memorize data**, it **learns general patterns of interaction** between inputs.\n",
        "\n",
        "---\n",
        "\n",
        "### üß† 2. Deep Network\n",
        "\n",
        "* A standard neural network (fully connected layers).\n",
        "* Learns **nonlinear, high-order patterns**.\n",
        "* It helps the model understand more abstract combinations of features like:\n",
        "\n",
        "  * \"If LH is high and insulin is high and Vitamin D3 is low, then PCOS is likely.\"\n",
        "\n",
        "‚û° This network **complements** the Cross Network by learning things the other can‚Äôt.\n",
        "\n",
        "---\n",
        "\n",
        "### üîó 3. Combined Output\n",
        "\n",
        "* DCN **merges** the outputs of the Cross and Deep networks.\n",
        "* This final merged result goes through a final prediction layer (e.g., predicting 1 = PCOS, 0 = no PCOS).\n",
        "\n",
        "---\n",
        "\n",
        "## üß™ Real-Life Example ‚Äî PCOS Diagnosis\n",
        "\n",
        "Imagine you‚Äôre working with patient data containing:\n",
        "\n",
        "* Age\n",
        "* BMI\n",
        "* Glucose Level\n",
        "* LH Hormone Level\n",
        "* AMH Level\n",
        "* Follicle Count (left & right ovaries)\n",
        "* Symptoms (e.g., skin darkening, hair growth)\n",
        "\n",
        "#### Traditional models might:\n",
        "\n",
        "* Just add up weights: `0.3 √ó LH + 0.6 √ó BMI + ‚Ä¶`\n",
        "\n",
        "#### DCN does something deeper:\n",
        "\n",
        "* **Cross Network** might learn:\n",
        "\n",
        "  * `BMI √ó AMH` is a strong indicator\n",
        "  * `Glucose √ó LH √ó Skin Darkening` is a risky pattern\n",
        "* **Deep Network** might learn:\n",
        "\n",
        "  * ‚ÄúIf BMI is high and Vitamin D3 is low, that often correlates with AMH imbalance.‚Äù\n",
        "\n",
        "‚û° Together, the model becomes **much more accurate**, **without you needing to manually build those interactions**.\n",
        "\n",
        "---\n",
        "\n",
        "## üìà Benefits of Using DCN\n",
        "\n",
        "| Feature                              | Benefit                                             |\n",
        "| ------------------------------------ | --------------------------------------------------- |\n",
        "| ‚úÖ No need for manual feature crosses | Learns them on its own                              |\n",
        "| ‚úÖ Interpretable                      | You can trace learned feature combinations          |\n",
        "| ‚úÖ Efficient                          | Uses fewer parameters than complex DNNs             |\n",
        "| ‚úÖ Works on small to medium datasets  | Especially useful in medicine or research           |\n",
        "| ‚úÖ Generalizes well                   | Captures both linear, cross, and nonlinear patterns |\n",
        "\n",
        "---\n",
        "\n",
        "## üö´ What DCN Does *Not* Need\n",
        "\n",
        "* No attention mechanism (unlike DAN)\n",
        "* No sequence or time-series input\n",
        "* No handcrafted interaction terms\n",
        "\n",
        "It works with **plain tabular data** ‚Äî which makes it perfect for medical data, surveys, e-commerce data, and more.\n",
        "\n",
        "---\n",
        "\n",
        "## üìö Summary\n",
        "\n",
        "| Aspect                   | Description                                        |\n",
        "| ------------------------ | -------------------------------------------------- |\n",
        "| **Model Name**           | Deep & Cross Network (DCN)                         |\n",
        "| **Invented By**          | Google, 2017                                       |\n",
        "| **Data Type**            | Structured/tabular (non-sequential)                |\n",
        "| **Learns Interactions?** | ‚úÖ Explicit and implicit                            |\n",
        "| **Architecture**         | Cross Network + Deep MLP Network                   |\n",
        "| **Use Cases**            | PCOS, CTR, financial scoring, health risk analysis |\n",
        "| **Strengths**            | No manual feature crosses, interpretable, accurate |\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "WyCbxgnT2t9b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![dan.jpg](data:image/jpeg;base64,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)"
      ],
      "metadata": {
        "id": "zIJfVS5j28pz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### üåü Explicit Learning:\n",
        "\n",
        "* The model **clearly learns specific patterns** you can see.\n",
        "* Example: DCN learns that `BMI √ó Glucose` is important.\n",
        "* Think of it like **clearly writing out a rule**:\n",
        "  ‚Üí \"If BMI is high and Glucose is high, then risk is high.\"\n",
        "\n",
        "---\n",
        "\n",
        "### üåü Implicit Learning:\n",
        "\n",
        "* The model **learns hidden patterns** without showing exact rules.\n",
        "* Example: A deep neural network figures out a pattern using layers, but you can‚Äôt easily tell what features interacted.\n",
        "* It‚Äôs like **a gut feeling** the model develops.\n",
        "\n",
        "---\n",
        "\n",
        "### üéØ Simple Analogy:\n",
        "\n",
        "| Type     | Like...                                            |\n",
        "| -------- | -------------------------------------------------- |\n",
        "| Explicit | \"I saw the rule written clearly.\"                  |\n",
        "| Implicit | \"I just felt it was right, but can't explain why.\" |\n",
        "\n",
        "---\n",
        "\n",
        "So in DCN:\n",
        "\n",
        "* **Cross Network ‚Üí Explicit learning** (you can trace the feature interactions)\n",
        "* **Deep Network ‚Üí Implicit learning** (hidden nonlinear patterns)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "sYofGmS0yvM_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o1SYmoo61w_z"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, Model\n",
        "\n",
        "class CrossLayer(layers.Layer):\n",
        "    def __init__(self, input_dim):\n",
        "        super().__init__()\n",
        "        self.w = self.add_weight(shape=(input_dim,), initializer='random_normal', trainable=True)\n",
        "        self.b = self.add_weight(shape=(input_dim,), initializer='zeros', trainable=True)\n",
        "\n",
        "    def call(self, x0, x):\n",
        "        xw = tf.reduce_sum(x * self.w, axis=1, keepdims=True)\n",
        "        return x0 * xw + self.b + x\n",
        "\n",
        "class DeepCrossNetwork(Model):\n",
        "    def __init__(self, input_dim):\n",
        "        super().__init__()\n",
        "        self.cross1 = CrossLayer(input_dim)\n",
        "        self.cross2 = CrossLayer(input_dim)\n",
        "        self.dense1 = layers.Dense(64, activation='relu')\n",
        "        self.dense2 = layers.Dense(32, activation='relu')\n",
        "        self.output_layer = layers.Dense(1, activation='sigmoid')\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x0 = inputs\n",
        "        x = self.cross1(x0, x0)\n",
        "        x = self.cross2(x0, x)\n",
        "        deep_out = self.dense1(x0)\n",
        "        deep_out = self.dense2(deep_out)\n",
        "        combined = tf.concat([x, deep_out], axis=1)\n",
        "        return self.output_layer(combined)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load Titanic data (example)\n",
        "df = pd.read_csv('titanic.csv')\n",
        "\n",
        "# Preprocessing (simple example)\n",
        "df['Age'].fillna(df['Age'].median(), inplace=True)\n",
        "df['Fare'].fillna(df['Fare'].median(), inplace=True)\n",
        "df['Embarked'].fillna('S', inplace=True)\n",
        "\n",
        "# Select features and target\n",
        "features = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']\n",
        "X = df[features]\n",
        "y = df['Survived'].values\n",
        "\n",
        "# Encode categorical variables\n",
        "X = pd.get_dummies(X, columns=['Sex', 'Embarked'])\n",
        "\n",
        "# Scale numerical features\n",
        "scaler = StandardScaler()\n",
        "for col in ['Age', 'Fare']:\n",
        "    X[col] = scaler.fit_transform(X[[col]])\n",
        "\n",
        "X = X.values.astype(np.float32)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Define your DAN model (as shared earlier)...\n",
        "\n",
        "input_dim = X_train.shape[1]\n",
        "model = DeepCrossNetwork(input_dim=input_dim)\n",
        "\n",
        "# Compile\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train\n",
        "model.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs=50, batch_size=32)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = (model.predict(X_valid) > 0.5).astype(int)\n",
        "print(\"Validation Accuracy:\", accuracy_score(y_valid, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ygkXGtS23SP4",
        "outputId": "781cafd2-2fd7-4dd3-c39a-316395699310"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-5-1452745367.py:12: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['Age'].fillna(df['Age'].median(), inplace=True)\n",
            "/tmp/ipython-input-5-1452745367.py:13: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['Fare'].fillna(df['Fare'].median(), inplace=True)\n",
            "/tmp/ipython-input-5-1452745367.py:14: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['Embarked'].fillna('S', inplace=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.5895 - loss: 0.6977 - val_accuracy: 0.6369 - val_loss: 0.6023\n",
            "Epoch 2/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7134 - loss: 0.5350 - val_accuracy: 0.7374 - val_loss: 0.5431\n",
            "Epoch 3/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7811 - loss: 0.4926 - val_accuracy: 0.7598 - val_loss: 0.5016\n",
            "Epoch 4/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7907 - loss: 0.4799 - val_accuracy: 0.7709 - val_loss: 0.4830\n",
            "Epoch 5/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7967 - loss: 0.4532 - val_accuracy: 0.7933 - val_loss: 0.4667\n",
            "Epoch 6/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8160 - loss: 0.4237 - val_accuracy: 0.7933 - val_loss: 0.4627\n",
            "Epoch 7/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8086 - loss: 0.4190 - val_accuracy: 0.7989 - val_loss: 0.4589\n",
            "Epoch 8/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7983 - loss: 0.4434 - val_accuracy: 0.8045 - val_loss: 0.4533\n",
            "Epoch 9/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8169 - loss: 0.4170 - val_accuracy: 0.8045 - val_loss: 0.4529\n",
            "Epoch 10/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7993 - loss: 0.4396 - val_accuracy: 0.7989 - val_loss: 0.4496\n",
            "Epoch 11/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7970 - loss: 0.4283 - val_accuracy: 0.7989 - val_loss: 0.4472\n",
            "Epoch 12/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8117 - loss: 0.4248 - val_accuracy: 0.7989 - val_loss: 0.4451\n",
            "Epoch 13/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8105 - loss: 0.4239 - val_accuracy: 0.8045 - val_loss: 0.4386\n",
            "Epoch 14/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7976 - loss: 0.4223 - val_accuracy: 0.7989 - val_loss: 0.4408\n",
            "Epoch 15/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8224 - loss: 0.4008 - val_accuracy: 0.8101 - val_loss: 0.4368\n",
            "Epoch 16/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8517 - loss: 0.3705 - val_accuracy: 0.7933 - val_loss: 0.4372\n",
            "Epoch 17/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8200 - loss: 0.4164 - val_accuracy: 0.8101 - val_loss: 0.4324\n",
            "Epoch 18/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8495 - loss: 0.3738 - val_accuracy: 0.8156 - val_loss: 0.4359\n",
            "Epoch 19/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8251 - loss: 0.4055 - val_accuracy: 0.8101 - val_loss: 0.4322\n",
            "Epoch 20/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8170 - loss: 0.4169 - val_accuracy: 0.7933 - val_loss: 0.4345\n",
            "Epoch 21/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8217 - loss: 0.4366 - val_accuracy: 0.8045 - val_loss: 0.4331\n",
            "Epoch 22/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8425 - loss: 0.3903 - val_accuracy: 0.8101 - val_loss: 0.4304\n",
            "Epoch 23/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8335 - loss: 0.3877 - val_accuracy: 0.8045 - val_loss: 0.4270\n",
            "Epoch 24/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8205 - loss: 0.4050 - val_accuracy: 0.8156 - val_loss: 0.4366\n",
            "Epoch 25/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8529 - loss: 0.3820 - val_accuracy: 0.8045 - val_loss: 0.4277\n",
            "Epoch 26/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8413 - loss: 0.3913 - val_accuracy: 0.8156 - val_loss: 0.4239\n",
            "Epoch 27/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8358 - loss: 0.3970 - val_accuracy: 0.8212 - val_loss: 0.4380\n",
            "Epoch 28/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8651 - loss: 0.3472 - val_accuracy: 0.7933 - val_loss: 0.4397\n",
            "Epoch 29/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8327 - loss: 0.3862 - val_accuracy: 0.8212 - val_loss: 0.4221\n",
            "Epoch 30/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8448 - loss: 0.3764 - val_accuracy: 0.8268 - val_loss: 0.4237\n",
            "Epoch 31/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8472 - loss: 0.3802 - val_accuracy: 0.8212 - val_loss: 0.4212\n",
            "Epoch 32/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8568 - loss: 0.3691 - val_accuracy: 0.8268 - val_loss: 0.4200\n",
            "Epoch 33/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8604 - loss: 0.3615 - val_accuracy: 0.8212 - val_loss: 0.4215\n",
            "Epoch 34/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8573 - loss: 0.3559 - val_accuracy: 0.8324 - val_loss: 0.4236\n",
            "Epoch 35/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8336 - loss: 0.3968 - val_accuracy: 0.8212 - val_loss: 0.4179\n",
            "Epoch 36/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8371 - loss: 0.3878 - val_accuracy: 0.8101 - val_loss: 0.4195\n",
            "Epoch 37/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8729 - loss: 0.3241 - val_accuracy: 0.8268 - val_loss: 0.4202\n",
            "Epoch 38/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8591 - loss: 0.3524 - val_accuracy: 0.7989 - val_loss: 0.4257\n",
            "Epoch 39/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8274 - loss: 0.3990 - val_accuracy: 0.8324 - val_loss: 0.4260\n",
            "Epoch 40/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8337 - loss: 0.3882 - val_accuracy: 0.8324 - val_loss: 0.4178\n",
            "Epoch 41/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8566 - loss: 0.3449 - val_accuracy: 0.8101 - val_loss: 0.4195\n",
            "Epoch 42/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8580 - loss: 0.3399 - val_accuracy: 0.8268 - val_loss: 0.4190\n",
            "Epoch 43/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8409 - loss: 0.3738 - val_accuracy: 0.8324 - val_loss: 0.4150\n",
            "Epoch 44/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8585 - loss: 0.3504 - val_accuracy: 0.8324 - val_loss: 0.4200\n",
            "Epoch 45/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8316 - loss: 0.3926 - val_accuracy: 0.8156 - val_loss: 0.4237\n",
            "Epoch 46/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8457 - loss: 0.3678 - val_accuracy: 0.7989 - val_loss: 0.4220\n",
            "Epoch 47/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8337 - loss: 0.3709 - val_accuracy: 0.8212 - val_loss: 0.4175\n",
            "Epoch 48/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8494 - loss: 0.3695 - val_accuracy: 0.8268 - val_loss: 0.4172\n",
            "Epoch 49/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8643 - loss: 0.3305 - val_accuracy: 0.8268 - val_loss: 0.4245\n",
            "Epoch 50/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8483 - loss: 0.3673 - val_accuracy: 0.8156 - val_loss: 0.4192\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Validation Accuracy: 0.8156424581005587\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# **DAN vs DCN ‚Äî Side-by-Side Comparison**\n",
        "\n",
        "| Feature                        | **DAN (Deep Attention Network)**                                                             | **DCN (Deep & Cross Network)**                                                                         |\n",
        "| ------------------------------ | -------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------ |\n",
        "| üß† **Core Idea**               | Learns **which parts of input to focus on** using attention                                  | Learns **explicit and implicit feature interactions** via dual paths                                   |\n",
        "| üîÅ **Input Type**              | **Sequential or contextual data** (e.g., user behavior history, time-series, logs)           | **Tabular/structured data** (e.g., medical, finance, surveys)                                          |\n",
        "| üîç **Mechanism**               | Uses **attention** to weigh the importance of input elements (e.g., past events or features) | Uses **cross layers** to explicitly compute feature combinations (e.g., `BMI √ó Insulin`) + deep layers |\n",
        "| üí° **What it learns**          | Which features or time steps are **more relevant** (dynamically)                             | Explicitly learns how features **interact**, and models high-order **nonlinear patterns**              |\n",
        "| üî¨ **Example Use Case**        | \"Which of a user's previous clicks influence the current ad the most?\"                       | \"Do combinations like `LH √ó AMH` or `BMI √ó Glucose` indicate PCOS?\"                                    |\n",
        "| üîß **Requires sequence data?** | ‚úÖ **Yes (usually)**                                                                          | ‚ùå **No**                                                                                               |\n",
        "| ‚öôÔ∏è **Architecture**            | Embedding ‚Üí Attention Layer ‚Üí MLP ‚Üí Output                                                   | Cross Network ‚Üí Deep MLP ‚Üí Concatenate ‚Üí Output                                                        |\n",
        "| üìä **Best For**                | CTR prediction, recommender systems, behavior modeling                                       | Medical diagnosis, fraud detection, sales prediction, structured tabular data                          |\n",
        "| üìà **Interpretability**        | Attention weights can show **importance of each input**                                      | Cross terms can be traced to specific **feature interactions**                                         |\n",
        "| üß™ **Example Model**           | DIN (Deep Interest Network), DIEN, AutoInt, FiBiNET                                          | DCN (Deep & Cross Network), DCN-V2                                                                     |\n",
        "\n",
        "---\n",
        "\n",
        "### üß† Visual Summary:\n",
        "\n",
        "```\n",
        "DAN:\n",
        " [Seq1, Seq2, Seq3, Seq4]\n",
        "     ‚Üì Attention\n",
        "[Weighted focus on important elements]\n",
        "     ‚Üì\n",
        "    MLP\n",
        "     ‚Üì\n",
        "  Prediction\n",
        "\n",
        "DCN:\n",
        "      Features\n",
        "         ‚Üì\n",
        "+------------------+\n",
        "| Cross Layers     |  --> Learns x1*x2, x2*x3, etc.\n",
        "| Deep MLP Layers  |  --> Learns non-linear patterns\n",
        "+------------------+\n",
        "         ‚Üì\n",
        "   Concatenate\n",
        "         ‚Üì\n",
        "     Prediction\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### üéØ Final Thoughts for You, Pookie:\n",
        "\n",
        "| If your data looks like‚Ä¶              | Use this model |\n",
        "| ------------------------------------- | -------------- |\n",
        "| User behavior over time               | **DAN**        |\n",
        "| Single patient record with lab values | **DCN**        |\n",
        "| Purchase history logs                 | **DAN**        |\n",
        "| Insurance application form            | **DCN**        |\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "XAq-xZeT-BTW"
      }
    }
  ]
}