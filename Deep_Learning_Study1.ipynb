{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNhVQ+Fsv3fDhgv14be02EY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/samiha-mahin/A_Deep_Learning_Repo/blob/main/Deep_Learning_Study1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**TabNet**\n",
        "\n",
        "## üß† What is TabNet?\n",
        "\n",
        "**TabNet** is a **deep learning architecture designed for tabular data**, introduced by Google Cloud AI researchers. Unlike traditional models like XGBoost or Random Forests, TabNet learns to select **important features at each decision step** using **sequential attention**.\n",
        "\n",
        "TabNet is especially useful when:\n",
        "\n",
        "* You have **structured/tabular data** (like CSV files or dataframes).\n",
        "* You want to **preserve interpretability**.\n",
        "* You want the **power of deep learning**, but with **explainability like tree-based models**.\n",
        "\n",
        "---\n",
        "\n",
        "## üß© Key Concepts\n",
        "\n",
        "| Concept                      | Explanation                                                           |\n",
        "| ---------------------------- | --------------------------------------------------------------------- |\n",
        "| **Sequential Attention**     | At each step, the model learns which features to focus on.            |\n",
        "| **Sparse Feature Selection** | Uses attention masks to focus only on relevant features.              |\n",
        "| **Interpretable**            | Can visualize which features were important for each prediction.      |\n",
        "| **End-to-End Learning**      | All parts of the model are trained together like a normal neural net. |\n",
        "\n",
        "---\n",
        "\n",
        "## üî® Architecture Overview\n",
        "\n",
        "### Components:\n",
        "\n",
        "1. **Encoder**: Transforms input into a decision representation.\n",
        "2. **Attentive Transformer**: Learns which features to select next.\n",
        "3. **Decision Step**: Makes a partial decision using selected features.\n",
        "4. **Aggregation**: Combines all decision steps to make the final prediction.\n",
        "\n",
        "---\n",
        "\n",
        "## üìä Example: TabNet on a Health Dataset (e.g., PCOS or Diabetes)\n",
        "\n",
        "Let‚Äôs say we have a dataset:\n",
        "\n",
        "| Age | BMI | Glucose | Insulin | PCOS (Yes/No) |\n",
        "| --- | --- | ------- | ------- | ------------- |\n",
        "| 25  | 30  | 140     | 15      | Yes           |\n",
        "| 30  | 22  | 110     | 6       | No            |\n",
        "| ... | ... | ...     | ...     | ...           |\n",
        "\n",
        "### üß¨ Goal: Classify whether a person has PCOS.\n",
        "\n",
        "---\n",
        "\n",
        "### ‚úÖ Step-by-Step Use with PyTorch TabNet\n",
        "\n",
        "```python\n",
        "from pytorch_tabnet.tab_model import TabNetClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# 1. Load your data\n",
        "df = pd.read_csv(\"pcos_data.csv\")\n",
        "\n",
        "# 2. Preprocess\n",
        "X = df.drop(\"PCOS\", axis=1).values\n",
        "y = LabelEncoder().fit_transform(df[\"PCOS\"])  # Yes=1, No=0\n",
        "\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "# 3. Train TabNet\n",
        "model = TabNetClassifier()\n",
        "model.fit(\n",
        "    X_train=X_train, y_train=y_train,\n",
        "    eval_set=[(X_valid, y_valid)],\n",
        "    eval_metric=['accuracy'],\n",
        "    max_epochs=100,\n",
        "    patience=10,\n",
        "    batch_size=256, virtual_batch_size=128,\n",
        ")\n",
        "\n",
        "# 4. Predict\n",
        "preds = model.predict(X_valid)\n",
        "print(\"Accuracy:\", accuracy_score(y_valid, preds))\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### üîç Interpretation: Which features mattered?\n",
        "\n",
        "```python\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Explain instance-level decisions\n",
        "explain_matrix, masks = model.explain(X_valid)\n",
        "\n",
        "# Visualize first decision step's mask\n",
        "plt.imshow(masks[0][0].reshape(1, -1), cmap='viridis')\n",
        "plt.title(\"Feature importance at first step for first row\")\n",
        "plt.yticks([])\n",
        "plt.colorbar()\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## üìà Performance\n",
        "\n",
        "TabNet is competitive with:\n",
        "\n",
        "* **XGBoost**\n",
        "* **LightGBM**\n",
        "* **CatBoost**\n",
        "\n",
        "But can outperform them when:\n",
        "\n",
        "* The dataset is **large** and **complex**.\n",
        "* There's a need for **feature interpretability** and **end-to-end deep learning**.\n",
        "\n",
        "---\n",
        "\n",
        "## üî¨ Summary\n",
        "\n",
        "| Feature          | TabNet                                        |\n",
        "| ---------------- | --------------------------------------------- |\n",
        "| Data Type        | Tabular                                       |\n",
        "| Attention        | Yes                                           |\n",
        "| Interpretability | High                                          |\n",
        "| Deep Learning    | Yes                                           |\n",
        "| Handles Missing  | Yes (with proper preprocessing)               |\n",
        "| Use Cases        | Health, Finance, Fraud Detection, Sensor Data |\n",
        "\n",
        "---\n",
        "\n",
        "## üöÄ Bonus Use Case: Predicting Fraud\n",
        "\n",
        "Imagine you‚Äôre using TabNet on a dataset like:\n",
        "\n",
        "| Amount | Time | Country | Card Type | Fraud (Y/N) |\n",
        "| ------ | ---- | ------- | --------- | ----------- |\n",
        "\n",
        "TabNet will:\n",
        "\n",
        "1. Learn that **Time** and **Card Type** matter more in the 1st step.\n",
        "2. Learn that **Amount** becomes important in the 2nd step.\n",
        "3. Combine decisions to output **Fraud = Yes** with a **probability score**.\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "WF7UKASWYa5s"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wMVpk3b0X4k8"
      },
      "outputs": [],
      "source": []
    }
  ]
}